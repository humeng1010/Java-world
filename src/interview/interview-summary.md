---
title: 面试总结篇

---
> 参照个人的简历准备的面试资料



## 专业技能

- Java基础：熟练掌握 Java 编程语言，熟悉常用集合类、面向对象、多线程、反射、IO
- 并发编程：熟悉 Java 并发编程，了解 synchornized、ThreadLocal、CAS、AQS、线程池 等
- 关系型数据库：熟悉 MySQL 和 SQL 语句的编写，掌握 MySQL 中的索引、事务、mvcc等常见知识 
- 非关系型数据库：熟悉 Redis 的使用，能够通过 Redis 实现分布式锁、缓存，并了解 Redis 的持久化策略以及数据过期策略，了解缓存穿透，击穿，雪崩的问题 
- 消息队列：熟悉 RocketMQ 的基本用法，了解如何解决消息顺序消费、消息的重复消费以及消息堆积的问题
- 开源框架：熟悉 SSM + SpringBoot 开发框架，能够使用 MyBatis Plus + MyBatis X 自动生成基础的 CRUD 代 码，熟悉 IOC 、AOP 、Bean 的生命周期、Bean 的循环依赖、SpringBoot 的自动装配原理 等知识
- 开发工具：熟练使用 Maven、Git、IDEA、 Docker 等开发工具
- 前端技术：熟悉 HTML 、CSS 、JavaScript 、Axios 、 Vue 等前端技术

## 简历模板

![image-20230918123333783](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202309181233001.png)

[点击查看模板](https://www.mujicv.com/jianlimoban/c124a10e0db5e4b9/)

## 项目经历

### 胖达 API 开放平台

`Spring Boot` `Spring Cloud Gateway` `MySQL` `MyBatis-Plus` `Redis` `Dubbo` `nacos`  `React`      

2023.07-至今

- 项目描述：
	基于 React + Spring Boot + Dubbo + Gateway 的 API 接口开放调用平台。
	管理员可以接入并发布接口；用户可以调用接口、浏览接口、在线调试，并通过客户端 SDK 轻松调用接口。

- 技术要点：

	- 根据业务流程，将整个项目后端划分为 web 系统、模拟接口、公共模块、客户端 SDK、API 网关这 5 个子项目，并使用 Maven 进行多模块依赖管理。
  
	- 为防止接口被恶意调用，设计 API 签名认证算法，为用户分配唯一 ak / sk 以鉴权，保障调用的安全性、可溯源性。
  
	- 为解决开发者调用成本过高的问题，基于 Spring Boot Starter 开发了客户端 SDK，用户只需在项目中引入 SDK 即可实现一行代码调用接口，提高开发体验。
  
	- 选用 Spring Cloud Gateway 作为 API 网关，实现了路由转发、访问控制、流量染色，并集中处理签名校验、请求参数校验、接口调用统计等业务逻辑，提高系统的安全性，便于系统的开发维护。
  
	- 为解决多个子系统内代码大量重复的问题，抽象模型层和业务层代码为公共模块，使用Nacos作为服务注册中心，Dubbo RPC 框架实现服务间的高性能接口调用，大幅减少重复代码。



#### 你的项目中使用了哪些技术栈？请分别介绍一下 Spring Boot、Dubbo、Gateway 在项目中的作用。

> 主观回答

项目技术栈：SSM + Spring Boot、Spring Cloud Gateway、Dubbo、Nacos、MySQL、Redis、MyBatis-Plus、Hutool 工具库。
Spring Boot：用于快速构建基础的后端项目，只需要修改配置文件，就能轻松整合 SSM、MySQL、Redis 等依赖。
Dubbo：分布式 RPC 框架，实现项目中不同模块的高性能相互调用，比如网关服务集中统计接口调用次数时通过 Dubbo 调用接口服务完成次数扣减。
Gateway：作为 API 网关，集中接受客户端的请求，并执行统一的安全认证、请求转发、流量控制、请求日志、公共业务等操作。

#### 你将后端项目划分为了多个子项目，请分别介绍这几个子项目的作用、以及它们之间是如何协作和交互的？

主观回答

API 开放平台分为 5 个子项目（核心模块），分别为：

api-backend：核心业务后端，负责用户和接口管理等核心业务功能

api-gateway：API 网关服务，负责集中的路由转发、统一鉴权、统一业务处理、访问控制等

api-common：公共模块，包括各其他模块中需要复用的方法、工具类、实体类、全局异常等

api-sdk-starter：客户端 SDK，封装了对各 API 接口的调用方法，降低开发者的使用成本。

api-interface：提供模拟 API 接口

交互流程：首先管理员创建接口后通过核心业务后端（api-backend）保存到数据库中。用户调用某个接口时，在自己的项目中引入客户端 SDK（api-client-sdk）并通过一行代码发起调用，请求会首先发送到 API 网关（api-gateway）进行用户的鉴权和接口调用统计，然后将请求转发到实际的 API 接口（api-interface）。

#### 请简要介绍 Maven 的基本概念、作用以及如何使用 Maven 进行多模块依赖管理和打包？

背诵类题目，但可以有主观回答

Maven 是一个开源的构建工具，用于管理 Java 项目的构建、依赖管理和项目生命周期。
本项目的所有依赖都是由 Maven 进行管理的，每个子项目都有自己的 pom.xml 进行管理。首先使用 mvn install 命令将 common 公共模块在本地打包，然后在其他子项目的 pom.xml 中引入该模块即可复用代码。每个子项目可以独立通过 mvn package 命令进行打包和部署。
Maven 还支持子父依赖多模块管理，通过 modules 配置给父项目指定子模块，从而实现统一的公共依赖和依赖版本定义。

#### 请介绍一下你是如何使用 MyBatis Plus 框架的 QueryWrapper 实现了对 MySQL 的灵活查询？

主观回答

MyBatis-Plus 是 MyBatis 的增强版框架，允许用户通过编程的方式构建复杂的查询条件，无需编写繁琐的 SQL 语句。
在本项目中，使用 MyBatis-Plus 的 QueryWrapper 查询条件构造器，通过链式调用的方式，灵活构造接口信息表的查询条件，比如使用 like 方法指定根据描述模糊查询、比如 orderBy 指定查询排序规则等，示例代码如下：

除了 QueryWrapper 外，MyBatis-Plus 还提供了 LambdaQueryWrapper，支持使用 Lambda 表达式来定义查询条件，更灵活。



#### 你在项目中使用了 Swagger + Knife4j 自动生成接口文档，请谈谈 Swagger 和 Knife4j 的作用和它们对项目开发的影响。

主观回答

Swagger 是一个用于自动构建和生成可交互接口文档的工具集。使用 Swagger 接口文档生成工具后，我不需要在开发完项目后手动编写一套接口文档，而是直接交由系统自动根据 Controller 接口层的代码自动生成文档，大幅节省时间。
使用 Swagger 生成的接口文档不仅能够分组查看请求参数和响应，还支持灵活的在线调试，可以直接通过界面发送请求来测试接口，提高开发调试效率。
此外，引入 Swagger 后，可以得到基于 OpenAPI 规范的接口定义 JSON，可以配合第三方工具来根据 JSON 自动生成前端请求代码、自动生成客户端调用 SDK 等。
Knife4j 是 Swagger 的增强版，能够生成更美观的 API 接口文档，并且提供了离线文档导出、接口分组排序等增强功能。（参考官网：https://doc.xiaominfo.com/docs/features）

#### 什么是 API 签名认证算法？它有什么作用？你又是如何实现它的？

前半句背诵类题目，后半句主观回答

API 签名认证算法是一种用于验证 API 请求的合法性和完整性的安全机制。
给接口使用 API 签名认证算法，可以增强 API 的安全性，防止未经授权的用户访问、防止恶意用户篡改请求数据。
实现步骤如下：
1
生成密钥对：给每个用户生成唯一的密钥对（accessKey 和 secretKey），并保存到数据库中，仅用户本人可查看自己的密钥对。
2
请求方生成签名： 请求方（客户端）使用 secretKey 对请求参数和数据进行签名，签名的内容包括请求参数、时间戳、随机数等，签名加密算法此处选择 MD5。
3
请求方发送请求：请求方将请求参数、签名、用户标识一起发送给 API 提供者，通常会把签名等元信息放到请求头参数中传递，注意千万不要传递 secretKey。
4
API 提供者验证签名：在 API 网关中，通过请求头获取到用户标识，根据标识到数据库中查找该用户对应的 accessKey 和 secretKey，并使用相同的签名算法生成签名，和请求中的签名进行比对，如果签名一致，则 API 提供者可以信任请求方，可以进行后续操作。

#### 你在项目中使用了 Spring Cloud Gateway 作为 API 网关，请解释一下 API 网关的应用场景，以及它在项目中的实际应用？

前半句背诵类题目，后半句主观回答

API 网关的主要应用场景：路由转发、统一鉴权认证、负载均衡、访问控制、流量染色、集中限流、统一监控和日志记录、全局跨域解决等。

在本项目中，使用 API 网关：
1）统一鉴权认证：应用 API 签名认证算法校验用户请求的合法性
2）公共业务逻辑：对每个接口的调用进行集中的统计
3）路由转发：前端发送请求到 API 网关，通过网关转发到实际的 API 接口
4）流量染色：给经过网关的请求加上特定的请求头参数，便于让实际的 API 服务确定请求来源及合法性

#### 你是如何基于 Spring Boot Starter 开发了客户端 SDK 的，讲述一下实现过程？

主观回答

0）首先明确客户端 SDK 的定位和功能，不要把 SDK 设计得过于繁重
1）引入相关依赖。如 spring-boot-configuration-processor、spring-boot-autoconfigure 等，用于开启自动导入以及给出配置文件的编辑提示
2）编写配置类，用于创建一个客户端 Bean 对象。给配置类添加 @ConfigurationProperties(prefix = "yuapi.client") 注解，用于自动从 Spring Boot 配置文件中读取配置。
3）注册配置类。在 resources/META-INF/spring.factories 文件中填写自动加载的配置类包路径
4）开发 SDK。像开发 Spring Boot 业务系统一样编写 SDK 功能代码
5）使用 SDK。在本地用 mvn install 命令打包 SDK，其他本地项目引入 SDK 即可使用
6）发布 SDK。在 Maven 中央仓库发布 SDK 包，其他开发者可通过 Maven 包索引在自己的项目中引入 SDK 并使用。

#### 用户如何使用你开发的客户端 SDK？讲述一下流程。

主观回答

1）在 API 开放平台进行注册登录，获取到开发者密钥 ak、sk
2）下载 SDK 代码到本地，或者从 Maven 中央仓库引入 pom 依赖
3）在项目的 application.yml 配置文件中填写客户端配置，比如 ak、sk 等
4）项目启动时，会自动创建一个客户端调用对象，可以直接在项目中注入该对象并使用

#### 有哪些客户端 SDK 的设计技巧？

背诵类题目，也可以主观回答

客户端 SDK 的目的是帮助开发者更轻松地使用我们系统提供的功能，因此在设计 SDK 时，要从开发者出发，提升开发者的调用体验。
可以从易用性、可理解性、可扩展性、高效稳定几个角度出发，多结合自己开发 SDK 的经历去回答，具体请见这篇文章：大厂 SDK 设计技巧 。

#### 什么是 RPC？为什么要使用 Dubbo RPC 框架，它有什么优势？

背诵类题目

RPC（Remote Procedure Call，远程过程调用）是一种用于实现分布式系统通信的协议和技术。它允许一个计算机程序调用另一个地址的函数或方法，就像本地函数调用一样，而不需要开发者显式地处理底层网络通信和数据序列化等问题。
Dubbo 是基于 Java 的高性能、轻量级的开源 RPC 框架，便于开发者轻松实现分布式系统和微服务架构。此外，Dubbo 还提供了服务治理等功能。
Dubbo RPC 框架的优势，简单来说就是性能高、协议多、功能强、生态好、易扩展。
具体的优势如下：
1
性能优秀：Dubbo 经过高度优化，具有出色的性能表现，适用于高并发和低延迟的场景。 
2
多协议支持：Dubbo 支持多种通信协议，可以根据不同的需求选择合适的协议，提供灵活性。 
3
服务治理：Dubbo 提供了丰富的服务治理功能，包括负载均衡、路由、容错处理等，有助于构建可靠的分布式系统。
4
生态系统：Dubbo 有广泛的生态系统和社区支持，提供了大量扩展和插件，满足各种应用场景的需求。 
5
可扩展性：Dubbo 的架构设计允许开发者轻松扩展和定制功能，以适应不同的业务需求。 

#### 你在项目中是如何使用 Dubbo RPC 框架的，讲述一下使用流程？

主观回答

在正式运用 Dubbo 到项目前，我先阅读了 Dubbo 的官方文档，按照快速启动文档跑通了基础的 RPC 调用 Demo，明确了注册中心、Maven 包等各依赖的版本号。
先在本地启动 Nacos 注册中心，然后在服务提供者和服务调用者项目引入 Dubbo 依赖（尽量引入相同的依赖和配置）、编写 Nacos 的连接配置、并且在项目启动类通过 @EnableDubbo 注解开启 Dubbo 支持。
编写服务提供者和服务调用客户端类，分别加上 @DubboService 和 @DubboReference 注解。
优先启动服务提供者项目，在 Nacos 控制台观察到服务注册信息，再启动服务调用者项目。

你在公共模块中抽象了模型层和业务层代码，请解释一下模型层和业务层的概念，并说明抽象公共模块的目的和好处。
背诵类题目，也可以主观回答

模型层（Model）：包括数据模型、实体类、业务封装对象等，一般不包含业务逻辑。 
业务层（Service）：包含了应用程序的业务逻辑和处理规则，一般会用到模型层的代码。
抽象公共模块的主要目的是为了复用代码。尤其是在微服务项目中，通常要把独立于业务的请求响应封装对象、全局异常处理类、常量、公共的数据模型抽象为公共模块，提供给各业务服务引入，便于项目的维护和理解。

#### 你通过 API 网关实现了流量染色技术，请介绍一下流量染色的概念、以及它的作用？

背诵类题目，也可以主观回答

流量染色是指根据请求的属性对请求进行分类和标记，从而进行特定的处理。
3 个关键概念：
1）请求分类：在请求层面的流量染色中，将请求分为不同的类别或组，通常基于请求的特性、内容、来源、用户身份等因素来进行分类。 
2）请求标记：每个请求被标记为属于特定的类别或组，这个标记可以是请求头中的特定字段、请求参数、或其他识别请求的方式。 
3）处理策略：为每个请求类别定义特定的处理策略，包括资源分配、访问控制、限流、缓存策略、安全性等。 

在本项目中，所有的外部请求都要先经过 Gateway 网关，由网关给请求加上特定的请求头参数（比如 Source = MyAPI），便于让下游的 API 服务确定请求来源及合法性。



### 篝火 - 伙伴匹配系统

`SpringBoot` `MySQL` `MyBatis-Plus` `Redis` `Redisson`  `Vue3`

2023.05 - 2023.07

- **项目描述**：
一个帮助大家找到志同道合的伙伴的移动端App，实现了登录注册、更新个人信息、按标签检索用户、推荐伙伴列表、匹配伙伴、组队等功能。独立开发完整前后端，项目上线地址：**[`hb.wuluwulu.cn`](http://hb.wuluwulu.cn)**
- **技术要点**：
	- 用户登录：使用 Redis 实现分布式 Session，解决集群间登录态同步问题；使用腾讯云COS云对象存储保存图片文件。
  - 为了明确接口的返回，自定义统一的错误码，并封装了 全局异常处理器 ，从而规范了异常返回、屏蔽了项目冗余的报错细节。
	- 使用 Redis 缓存首页高频访问的推荐用户信息列表，将接口的响应时长从 2.01 秒缩短至 76.92 毫秒。且通过自定义 Redis 序列化器来解决数据乱码、空间浪费的问题。
	- 为解决首次访问系统的用户主页加载过慢的问题，使用 Spring Scheduled 定时任务来实现缓存预热，并通过分布式锁保证多机部署时定时任务不会重复执行。
	- 为解决同一用户重复加入队伍、入队人数超限的问题，使用 Redisson 分布式锁来实现操作互斥，保证了接口幂等性。

#### 请介绍一下你在项目中使用的 Redis，它有哪些优势，为什么选择使用 Redis 实现分布式 Session？

> 前半句背诵类题目，后半句主观回答

Redis 是一个**开源的、基于内存的 K / V 存储**中间件。由于基于内存，其**读写性能非常高**，很适用于缓存。此外，**Redis 支持多种数据结构**、各类编程语言的客户端、支持持久数据，其生态也非常广泛。
本项目中，我**使用 Redis 分布式 Session 来代替 Tomcat 本地的 Session 存储**，能够在分布式多机场景下保证获取登录用户信息的一致性。用 Redis 实现分布式 Session 的优点是非常简单方便，只需要引入 Redis 和 spring-session-data-redis 依赖，然后在配置文件中指定 Redis 的地址和 session 的 store-type 为 redis，即可自动生效，不用自己额外编码。

#### 你在用户登录功能中提到使用 Hash 代替 String 存储用户信息，这样的做法有什么好处？在实际应用中，Hash 与 String 存储方式有哪些区别？

> 主观回答

Redis 的 Hash 结构采用 key / value 键值对的形式存储数据，使用 Redis 的 Hash 来存储用户信息后，能够很方便地对用户每个属性进行独立的更新和查询操作，而不是更新和返回整个 JSON 字符串，性能会更高。
举个例子，你想要获取用户的昵称（就 4 个字符串），但是用户的简介有 100 KB 的大小。如果用 Hash 结构，可以只获取昵称，网络传输的内容大小就很小；而如果用 String 结构整体存储，网络传输数据时会把所有的用户信息都返回出来，增加传输开销。
此外，相比于直接在 Spring Boot 中使用 String 类型存储用户信息，使用 Hash 结构不用额外存储序列化对象信息，可以一定程度上节省内存。



#### 你是如何自定义线程池的？如何合理设置线程池的参数？

背诵类题目，但是最好实践过

项目中，我使用 ThreadPoolExecutor 实现灵活的自定义线程池，并通过 ArrayBlockingQueue 存放任务。针对每类不同的业务，我分别定义不同的线程池，让它们互不影响。
示例代码：

自定义线程池参数如下：
1
核心线程数（corePoolSize）：线程池中一直保持活动的线程数。可以使用corePoolSize方法来设置。一般情况下，可以根据系统的资源情况和任务的特性来设置合适的值。
2
最大线程数（maximumPoolSize）：线程池中允许存在的最大线程数。可以使用maximumPoolSize方法来设置。如果所有线程都处于活动状态，而此时又有新的任务提交，线程池会创建新的线程，直到达到最大线程数。
3
空闲线程存活时间（keepAliveTime）：当线程池中的线程数量超过核心线程数时，如果这些线程在一定时间内没有执行任务，则这些线程会被销毁。可以使用keepAliveTime和TimeUnit方法来设置。
4
阻塞队列（workQueue）：用于存放等待执行的任务的阻塞队列。可以根据任务的特性选择不同类型的队列，如LinkedBlockingQueue、ArrayBlockingQueue等。默认情况下，使用无界阻塞队列，即LinkedBlockingQueue，但也可以根据需要设置有界队列。
5
线程工厂（threadFactory）：用于创建线程的工厂。可以通过实现ThreadFactory接口自定义线程的创建逻辑。
6
拒绝策略（rejectedExecutionHandler）：当线程池无法接受新的任务时，会根据设置的拒绝策略进行处理。常见的拒绝策略有AbortPolicy、DiscardPolicy、DiscardOldestPolicy和CallerRunsPolicy。

我是根据任务的类型以及消耗资源的情况来调整线程池的参数。比如针对更消耗 CPU 资源的计算密集型任务，我会将核心线程数设置为和 CPU 核心数相同，充分利用系统资源；针对更消耗网络等 IO 的 IO 密集型任务，我会将核心线程数设置得更大，比如 CPU 核心数的 2 - 4 倍，能够增加并发度、并且提高 CPU 的利用率。

有一个经验值公式，其中 N 为 CPU 核心数：CPU 密集型任务，核心线程数设置为 N（或 N + 1）；IO 密集型任务，核心线程数设置为 2N。



#### 你在使用 Redis 缓存高频访问用户信息时提到了自定义序列化器，为什么需要自定义序列化器，以及自定义序列化器的实现方式？

主观回答

由于 Spring Boot Data Redis 默认使用 JDK 序列化器，会将存储到 Redis 的键值对转化为字节数组，不利于在 Redis 可视化工具中阅读、并且不利于跨语言兼容，所以需要指定序列化器。
所以我通过新建 RedisTemplateConfig 配置类来创建自定义的 RedisTemplate Bean，并且通过 redisTemplate.setKeySerializer(RedisSerializer.string()) 指定了 Redis Key 的序列化方式。
示例代码如下：

#### 你在项目中是如何实现 Redis 缓存的？选用了哪种 Redis 数据结构？

主观回答

我的项目中，使用 Redis 缓存实现了登录用户信息的存储、主页推荐用户列表的存储。
具体的实现方式：
●
对于登录用户信息的存储，直接使用 spring-session-data-redis 依赖开启对 Redis 分布式 Session 的支持。
●
对于主页用户推荐列表的存储，我使用 Spring Data Redis 整合 Redis，并通过 RedisTemplate 来操作 Redis，根据业务类型设计了缓存 key 的规则，选用 string 数据结构来存储推荐用户列表。

#### 使用 Redis 缓存时，有哪些可能出现的常见问题？你又是如何解决的？

背诵类题目

建议先列举使用缓存可能出现的常见问题，然后再挑其中一点举例。
使用 Redis 缓存可能的常见问题：
1）缓存击穿： 缓存击穿指的是某个热门的缓存键在过期后，同时有大量并发请求到达，导致所有请求都穿透缓存直接访问数据库，造成数据库压力激增。解决方法包括： 
●
使用互斥锁来保护缓存访问，只允许一个线程重新生成缓存。
●
针对缓存失效时的并发请求使用分布式锁，确保只有一个线程重新生成缓存。
2）缓存雪崩： 缓存雪崩指的是大量缓存键在相同时间失效，导致大量请求落到数据库上，造成数据库压力激增。解决方法包括： 
●
为缓存键设置不同的失效时间，使失效时间分散。
●
使用热点数据预热，提前加载热门数据到缓存。
3）缓存过期问题： 缓存中的数据过期后可能会导致数据不一致或数据不可用。解决方法包括： 
●
设置合理的缓存失效时间，避免缓存数据长时间不更新。
●
使用缓存的时候检查数据是否过期，如果过期则重新生成缓存。
4）缓存内存问题： 如果缓存数据量很大，可能会导致内存占用过多。解决方法包括： 
●
设置合理的内存限制，避免缓存数据过多。
●
使用LRU（Least Recently Used）策略或淘汰算法来淘汰不常用的缓存数据。
5）缓存数据一致性问题： 缓存数据和数据库数据不一致。解决方法包括： 
●
使用缓存更新策略，当数据库数据发生变化时，及时更新缓存。
●
使用双写策略，即同时更新数据库和缓存，确保数据一致性。
6）缓存安全问题： 某些敏感数据可能不应该被缓存，如果被缓存可能引发安全问题。解决方法包括： 
●
避免缓存敏感数据。
●
使用加密或其他安全措施来保护缓存数据。
7）缓存监控和调优问题： 缓存需要监控和调优，以确保性能和稳定性。解决方法包括： 
●
使用监控工具来监测缓存的命中率、内存占用等性能指标。
●
定期调整缓存配置，优化性能。

在本项目中，我通过给不同的缓存设置不同的随机过期时间（N + n）来解决缓存雪崩问题。

#### 在解决首页加载过慢的问题中，你使用了 Spring Scheduler 定时任务和分布式锁，请解释一下定时任务的执行原理和此处分布式锁的作用。

主观回答

项目使用 Spring Scheduler 实现定时任务，我将每个任务定义为独立的 Job 类，并且给实际需要定时执行的方法增加 @Scheduled 注解来开启定时任务。
在 @Scheduled 注解中，我使用 crontab 表达式来定义执行定时任务的时间周期，Spring Scheduler 会根据这些定义，在时机到达时开启独立的线程来执行任务。
在分布式场景下，可能有多个服务器实例同时执行同一个定时任务，导致并发问题或重复执行，所以用分布式锁来保证定时任务执行的唯一性。当定时任务要执行时，先去抢锁，只有抢到锁的服务器实例才会执行定时任务。

#### 你在项目中使用 Redisson 分布式锁解决了接口幂等性的问题，请简要介绍一下 Redisson 分布式锁的使用场景和实现原理。

背诵类题目

Redisson 是一个基于 Redis 的数据网格，它提供了开箱即用的分布式锁功能，用于解决分布式环境下的并发控制问题。
比如在项目中，使用 Redisson 分布式锁保证接口幂等性，防止多个用户同时操作或重复提交带来的数据不一致。

Redisson 分布式锁的实现是基于 Redis 的 SETNX 命令和 Lua 脚本，具体的实现原理如下：
1
获取锁：当客户端请求获取锁时，Redisson 会向 Redis 发送一个 SETNX 命令，尝试将一个特定的键（锁的标识）设置为一个特定的值（客户端标识），并设置锁的超时时间。 
2
争用锁：如果多个客户端同时尝试获取同一个锁，只有一个客户端能够成功设置键的值，其他客户端的 SETNX 命令将失败，它们会继续尝试获取锁。 
3
锁超时：为了防止某个客户端获取锁后发生异常导致锁永远不会被释放，Redisson 设置了锁的超时时间。当锁的超时时间到达后，Redisson 会自动释放锁，允许其他客户端获取锁。 
4
释放锁：当客户端执行完锁保护的操作后，可以主动释放锁，这将删除锁的标识键，或者锁的自动超时也会导致锁的释放。 
5
锁的可重入性：Redisson 支持可重入锁，允许同一客户端多次获取同一个锁，然后多次释放锁。只有所有获取锁的次数都释放后，锁才会被完全释放。 
6
锁的续期：如果一个客户端在持有锁时，锁的超时时间即将到期，Redisson会自动为锁续期，防止锁在操作过程中被自动释放。 

#### 编辑距离算法是什么，它在你实现的用户匹配功能中起到了什么作用？请解释一下编辑距离算法的实现原理。

背诵类题目

编辑距离算法是一种用于度量两个字符串之间的相似度或差异性的算法，常用于字符串相似度比较、拼写检查等场景。
在用户匹配功能中，我使用编辑距离算法来计算用户输入的搜索关键词与已有用户信息的匹配程度，并按照相似度进行排序，从而实现最相似用户的推荐。
编辑距离算法的实现原理：https://blog.csdn.net/DBC_121/article/details/104198838，仅做了解即可，不用背诵。



#### 在项目中，你自主编写了 Dockerfile 来实现自动化镜像构建及容器部署，请介绍一下用 Docker 的优势？

背诵类题目

可以把 Docker 镜像想象成应用的安装包，我通过编写 Dockerfile 制作了项目的安装包，开发者可以使用该 Docker 镜像一键快速启动项目，无需手动安装 Java 等依赖项、并且手动输入启动 jar 包的命令，便于分发应用程序、并且提高应用部署效率。
此外，通过给 Docker 镜像打 tag，可以控制应用程序的版本，便于项目的持续发布和回滚。

#### 你在项目中使用 Knife4j 和 Swagger 自动生成后端接口文档，请解释一下 Swagger 的作用，以及在项目中使用 Swagger 的好处。

背诵类题目，也可以有主观回答

使用 Swagger 接口文档生成工具后，我不需要在开发完项目后手动编写一套接口文档，而是直接交由系统自动根据 Controller 接口层的代码自动生成文档，大幅节省时间。
使用 Swagger 生成的接口文档不仅能够分组查看请求参数和响应，还支持灵活的在线调试，可以直接通过界面发送请求来测试接口，提高开发调试效率。
此外，引入 Swagger 后，可以得到基于 OpenAPI 规范的接口定义 JSON，可以配合第三方工具来根据 JSON 自动生成前端请求代码、自动生成客户端调用 SDK 等。

## 个人介绍

面试官好，我叫xx，来自xxxx。

在大学期间利用课外时间自学Java语言，到目前已经熟练掌握了Java基础、SSM框架、SpringBoot、MySQL、Redis、MyBatisPlus，微服务和前端也都有一定的了解。

在大学期间我自己独立完成了一些项目，其中有API开放平台，做这个项目的目的是给后端用户提供方便的接口调用，其中我使用网关来做统一请求，路由转发，权限校验，并且自定义sdk，用户只需要引入sdk即可一行代码调用接口，该项目的技术难点是如何保证接口不被恶意调用 以及 避免请求重放给系统带来不必要的开销。

另外一个项目是伙伴匹配系统，做这个项目的目的是帮助用户寻找志同道合的人，可以查看用户的联系方式，并且提供组队和创建队伍的功能，方便用户查看整个队伍中的志同道合的人。该项目的前端使用的是vue3+vant组件库开发的，后端使用的是SpringBoot。并且呢该项目使用Docker容器技术部署到服务器上避免了配置复杂的环境。

说到业余爱好的话我会经常整理学习过的知识以及整理博客，在我的个人网站上已经发布了80多篇的个人博客。最后我一直都很想加入贵公司，非常期待能与大家成为同事。

## Redis篇

### 在你的项⽬中是怎么使⽤Redis的

1. 在我的项⽬中使⽤ Redis 配合 Spring 的 Redis-session，将⽤户的登录态存⼊ Redis，实现单点登录。

2. 对于系统的⾸⻚，为了加快响应速度，设置定时任务将⾸⻚数据缓存到 Redis中，避免了⾸⻚加载过慢⽤户体验差的情况。

3. 对于⽤户加⼊队伍的限制，使⽤ Redisson 作分布式锁，防⽌了⽤户恶意请求加⼊超出限制数量的队伍。



### 介绍一下缓存穿透，以及如何解决

缓存穿透：用户发送请求查询某个队伍详细信息，正常情况下首先查询缓存，如果缓存中存在则直接返回数据，如果缓存中不存在，则会查询数据库，数据库中查询到数据之后写到缓存中然后返回数据，如果数据库中也没有该数据，就会发生缓存穿透，即所查询的数据缓存中不存在，数据库中也不存在，会出现大量的请求请求到数据库这就是缓存穿透。

解决：在我的项目中，我是使用缓存空值的方法来解决缓存穿透的问题，优点是实现起来简单，缺点是可能会造成短暂的缓存与数据不一致的情况。当查询数据库中没有数据的时候，我们先缓存Redis中该id为key缓存一个空字符串，然后一定要设置一个合理的过期时间，然后返回不存在数据；当请求再次来到的时候，首先检查到Redis中该id对应的缓存是空字符串，直接返回数据不存在。

> 还有一种我了解的解决方案是布隆过滤器，布隆过滤器主要是检查一个元素是否在一个集合中，可以使用redisson实现的布隆过滤器。
>
> 底层是先初始化一个比较大的数组，里面存放二进制的0和1，在一开始全都是0，当一个key来了之后经过3次hash计算，然后模数组的长度找到对应的下标，把下标该为1，这样3个数组的位置就能确定一个key是否存在。
>
> 缺点是可能存在误判，这个我们可以设置误判率，大概不超过5%。为什么会有误判？因为数组长度是固定的，当有一个key经过3次hash计算后模数组长度得到的3个下标对应的都是1的时候就会直接认为该数据存在，但是实际不存在。



### 什么是缓存击穿，如何解决

缓存击穿：某个key设置了过期时间，当该key过期了，有大量的请求请求到该key，这些并发请求可能会瞬间把数据库压垮。

解决：我了解的有两种解决方案，分别是分布式锁，逻辑过期法。在项目中我使用分布式锁解决缓存击穿问题，具体方法是使用Redis的setnx关键字来实现分布式锁，首先大量的并发请求请求到一个key刚好在缓存中过期了，缓存中没有该数据则会请求数据库，在请求数据库之前使用Redis的setnx设置一个业务前缀：lock的key，如果有一个请求设置成功了，则其他的请求会再此处重试，我们让获取锁成功的去进行缓存重构，当然在缓存重构之前需要再次查询缓存是否存在数据，防止已经被其他线程缓存重构过了，完成之后需要手动删除该锁。要注意需要给lock设置一个合理的过期时间，防止出现死锁。这个过期时间需要根据具体的业务复杂度来设置，不能太短，防止业务还没有处理完毕就自动把锁释放了。

另一种是逻辑过期的方法解决缓存击穿，我们需要手动给热点key的数据中添加一个过期时间，在请求来到的时候，先查询缓存，然后检查缓存中的时间是否过期，如果没有过期则返回数据，如果已经过期，获取互斥锁，如果获取失败的直接先返回过期的数据，获取锁成功的线程执行缓存重构，同样在缓存重构之前需要进行二次校验判断是否被重构过了，如果没有重构则查询数据库更新逻辑过期时间和数据。



### 什么是缓存雪崩，如何解决

缓存雪崩：在同一时刻缓存中有大量的key同时过期或者Redis宕机，导致大量的请求打到数据库中，给数据库带来巨大的压力。

解决：给不同的key设置不同的过期时间，比如给不同的key设置一个固定的过期时间再加上一个随机的时间，这样就可以解决缓存同时过期的问题。如果Redis服务宕机可以设置Redis集群来提高Redis服务的可用性



### Redis作为缓存，mysql的数据如何与Redis数据保持一致性(双写一致性)

> 首先要结合自己的项目业务来分析，一致性高的场景下是一种方案，一致性不高允许出现延迟的场景可以采用另一种方案

双写一致性：当修改了数据库中的数据，也要同时更新缓存的数据，缓存的数据需要和数据库中的数据保持一致性。

在我的项目中，修改队伍信息是需要保证及时生效的，防止展示出来的还是原本的数据，可以采用**延迟双删**的方案来保证双写一致性。在修改之前先删除一次缓存，修改成功后然后再延迟删除缓存，这样的好处是可以极大的减少缓存不一致的情况。

另外一种方案是读操作和写操作都**加同一个分布式锁**，不过不太推荐这样做，因为保存到缓存中的数据都是读多写少的数据，这样做在大量请求的情况下会极大的影响到读的效率，可以使用**redisson封装的共享锁(读锁)和排它锁(写锁)**，在读操作的前后加上共享锁，在写操作的前后加上排它锁，这样在读的时候其他线程是不可以写的但是可以读，在写的时候其他线程不允许读写数据；这样可以保证强一致性。

---

另一种是允许数据短暂的不一致，在我别的项目中，Redis缓存店铺信息，店铺信息允许出现短暂的数据不一致情况，我采用的是给缓存的店铺设置一个短一点过期时间，当修改的时候不需要操作缓存，我们只需要等待缓存数据过期然后进行缓存重构即可更新缓存数据。我了解的还有另外一种方式：在修改数据之后，通过消息队列MQ通知缓存更新的服务来删除对应的数据，保证数据一致性；**这里需要保证MQ的消息可靠性**。



### Redis作为缓存，数据的持久化是怎么做的

在Redis中提供了两种持久化方案：RDB、AOF

RDB：把内存中的所有数据都记录到磁盘中。当Redis出现故障重启后，可以从磁盘中读取该RDB文件，恢复数据。

1.在Redis客户端中使用save可以在主进程中执行备份操作，不过会阻塞主进程，不推荐使用；另一种是使用bgsave，新开启一个子进程执行备份的操作。

2.也可以在Redis.conf文件中配置备份的触发条件例如save 300 10(300秒内如果有10个key修改了则触发备份，这里备份也是在子进程中执行的)

AOF：AOF全称Append Only File(追加文件)。Redis处理的**每一个写的命令都会记录在AOF文件**，可以看做是命令日志文件。

AOF默认是关闭的需要我们到配置文件中手动开启:

```sh
# 是否开启AOF功能，默认是no
appendonly yes
# AOF的文件的名称
appendfilename "appendonly.aof"
```

开启后可以配置AOF记录的频率：

```sh
# 每执行一次命令，立即记录到AOF中
appendfsync always
# 写命令执行完毕先放入AOF缓冲区，然后每隔1秒将缓冲区的数据写入到AOF文件中，默认方案
appendfsync everysec
# 写命令执行完毕后先放入AOF缓冲区，由操作系统决定何时将缓冲区内容写入AOF文件
appendfsync no
```

| 配置项   | 刷盘时机     | 优点                     | 缺点                         |
| -------- | ------------ | ------------------------ | ---------------------------- |
| always   | 同步刷盘     | 可靠性高，几乎不丢失数据 | 性能影响大                   |
| everysec | 每秒刷盘     | 性能适中                 | 最多丢失1秒的数据            |
| no       | 操作系统控制 | 性能最好                 | 可靠性差，可能丢失大量的数据 |

另外由于AOF记录的是命令序列，当我们对一个key进行多次的写操作的时候，最后一次会覆盖掉前面的例如

```sh
set k1 v1
set k2 v2
set k1 v3
```

k1的值就是v3了，但是AOF中还是记录了所有的操作，我们可以执行`bgrewriteaof`命令来让AOF执行重写来减少AOF文件的占用磁盘大小，重写后的如下：

```sh
mset k2 v2 k1 v3
```

总结：

> RDB 适合⽤于**数据集较⼤、备份、恢复数据和迁移数据**等场景；AOF 适合⽤于**数据可靠性要求⾼、数据恢复稳健**等场景。

![image-20230823103515194](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202308231035950.png)

### Redis数据过期策略

> 引出：如果Redis的key过期后会立即删除吗？
>
> `setex name jack 10`
>
> 数据过期之后就需要将数据从内存中删除，可以按照不同的规则删除，这种删除规则就称为数据的删除策略(数据过期策略)。惰性删除、定期删除

惰性删除：设置一个key当该key过期的时候，我们不需要管他，当需要该key的时候我们在检查他是否过期，如果已经过期了我们就删除掉他，反之则返回该key的值

优点：对CPU友好，我们只会在使用key的时候进行检查该key是否过期了，对于很多用不到的key不需要浪费时间进行检查是否过期

缺点：对内存不友好，当大量的key都过期了，但是没有人访问他，那么这些key就会一直存在内存中从而占用大量的内存

---

定期删除：每隔一段时间，我们就对一些key进行检查，删除里面过期的key。

定期清理有两种模式：SLOW模式和FAST模式。

优点：可以通过限制删除操作执行的时长和频率来减少删除操作对CPU的影响。定期删除能有效释放过期键占用的内存。

缺点：难以确定删除操作执行的时长和频率。

> Redis的过期删除策略：`惰性删除` + `定期删除` 两种策略进行配合使用

### Redis数据淘汰策略

当Redis中内存不够用的时候，此时再向Redis中添加新的key的时候，那么Redis就会按照某一种规则将内存中的数据删除掉，这种删除规则称之为内存的淘汰策略。

Redis常用的淘汰策略：

noeviction：当内存打到限制时，不删除任何键，⽽是返回错误；

**allkeys-lru**：当内存达到限制时，删除最近最少使⽤（LRU）的键；

volatile-lru：当内存达到限制时，删除设置了过期时间并且最近最少使⽤的键；

allkeys-random：当内存达到限制时，随机删除任意键；

volatile-random：当内存达到限制时，随机删除设置了过期时间的键；

volatile-ttl：当好内存达到限制时，删除设置了过期时间并且剩余⽣存时间最短的键。



### Redis分布式锁

Redis分布式锁主要利用Redis中的setnx来命令来实现。setnx命令是如果key不存在才能set对应的值，如果key存在了，则不能set对应的值

获取锁：

`set lock 1 nx ex 10` # 添加锁，nx是互斥、ex是设置锁的失效时间

释放锁：

`DEL lock` # 删除即可

### Redis分布式锁如何合理的控制锁的有效时间

1.根据具体业务估计设置锁的时长。不太靠谱

2.给锁续期，新开一个线程监视业务是否执行完毕，如果没有执行完毕并且锁的ttl快到期了，则自动续期。我的项目中使用的是redisson第三方依赖中的锁，该锁自带了**watchdog机制**可以自动续期。使用redisson加锁的时候，内部是通过Lua脚本进行实现的，可以保证命令的原子性。

### Redisson的锁可以重入吗？

> 锁的重入：方法a中加了锁，方法b中也加了同一把锁，在方法a中调用方法b如果可以成功加锁，并且释放锁则是可重入锁

Redisson的锁是可重入的锁，redisson锁根据线程唯一标识判断是否是同一个线程，如果线程相同，则是可以重入的，重入一次对应的value值+1。在redis中存储的时候使用hash数据类型，来存储线程信息和重入次数。

### Redisson锁可以解决主从数据的一致问题吗

不能解决，但是可以使用redisson提供的红锁RedLock，原理是给(n/2)+1个节点设置锁，这样主节点宕机即使没有来得及同步从节点从节点中也是有锁的，从而避免只在一个redis实例上加锁。



### 介绍Redis的主从同步

单节点的Redis的并发能力是有限的，想要提高Redis的并发能力，我们可以搭建Redis集群，实现一个主节点和若干个从节点，主节点主要负责写数据，从节点负责读数据



### 介绍一下Redis中哨兵的作用

Redis提供了哨兵机制来实现Redis主从集群的自动故障恢复。

监控：哨兵会不断的检查你的master和slave是否按照预期工作。

故障自动恢复：如果master故障，哨兵会将一个slave提升为master。当故障恢复后还是以新提升的master位主节点

通知：哨兵充当Redis客户端的服务发现来源，当集群发送故障转移时，会将最新的消息推送给Redis的客户端

哨兵怎么监控Redis的服务状态的？

哨兵基于心跳机制检测服务的状态，每一秒向集群的每一台实例发送ping命令：

主观下线：如果哨兵发现某一台实例没有在规定的时间内响应，则认为该实例主观下线；

客观下线：如果超过指定数量的哨兵(哨兵有多个)都认为该实例主观下线，则该实例就是客观下线了。指定数量最好是超过哨兵数量的一半



### Redis集群脑裂，该如何解决

集群脑裂：是由于主节点由于自身的网络问题导致主节点和从节点以及sentinel处于不同的网络分区，导致sentinel不能感知到master，所以通过选举的方式提升了一个从节点为主，这样就存在了两个master，就像大脑分裂了一样，这样就会导致客户端还是在老的主节点那里写入数据，新选举出来的主节点无法同步数据，当网络恢复的时候，原来的那个老的主节点就变成了新选举出来的主节点的从节点，**这时候从节点会同步主节点的数据，就会导致数据丢失**。

解决：由于脑裂是由网络等原因造成的，除了提高网络、硬件等方法外，主要通过增加以下配置，改善出现脑裂而引发的数据丢失问题。

```sh
# 要求至少有1个slave
min-slaves-to-write 1 
# 数据复制和同步的延迟不能超过10秒
min-slaves-max-lag 10 
```



### 分片集群解决海量数据的存储和高并发的写操作

分片集群特征：

集群中有多个master，每个master保存不同的数据

每个master都可以有多个slave节点

master之间通过ping监测彼此的健康状态

客户端可以访问集群的任意节点，最终都会被转发到正确的节点

> Redis分片集群中引入了哈希槽的概念，Redis集群有16384(2^14)个哈希槽，每个key通过**CRC16**校验之后对16384取模来决定放入到哪个槽位，集群的每一个节点负责一部分的哈希槽。



### Redis是单线程的，但是为什么还那么快？

1、纯内存操作
Redis 是基于内存的数据存储系统，绝⼤部分请求是纯粹的内存操作。

2、单线程操作，避免了频繁的上下⽂切换
Redis 的单线程操作是指，Redis 使⽤⼀个主线程来处理所有的客户端请求和数据操作，不会创建新的线程来处理请求。这种单线程模型的优点是可以避免多线程并发访问共享数据时的竞争和死锁问题，从⽽提⾼了 Redis 的性能和稳定性。此外，由于 Redis 的内存访问速度⾮常快，因此单线程处理请求也能够保证⾜够的性能。

3、采⽤了**⾮阻塞 I/O 多路复⽤**机制
为了实现单线程模型，Redis 使⽤了 IO 多路复⽤技术。IO 多路复⽤是指操作系统提供的⼀种 IO 模型，可以让⼀个进程同时监听多个 IO 事件（如读写事件），并在有事件发⽣时通知进程，从⽽实现并发处理 IO 事件。具体来说，在 Redis 中，客户端的请求是由⼀个单线程来处理的，⽽ IO 操作却是通过 epoll 多路复⽤技术实现的。



## MySQL篇

### 如何定位慢查询？

慢查询一般发生在如下查询场景：

- 聚合查询
- 多表查询
- 表数据量过大查询
- 深度分页查询

> 表象：页面加载过慢、接口压测响应时间大于一秒

方案一：使用开源工具

方案二：MySQL自带的慢日志查询

需要我们手动配置来开启慢日志查询。配置如下：

```sh
# 开启慢日志查询
slow_query_log=1
# 设置慢日志的时间为2秒，SQL语句执行时间超过2秒，就会被视为慢查询，记录慢查询日志
long_query_time=2
```

配置完毕后重启，当有慢查询的时候，就会在`/var/lib/mysql/localhost-slow.log`中记录查询超过2秒的sql

![image-20230824094928081](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202308240949323.png)

> 我们在MySQL中开启了慢日志查询，我们设置的值是2秒钟，一旦sql执行超过了我们设置的2秒钟就会被记录到日志中。(调试阶段)

### 如何分析慢查询？

在sql查询语句前面加上explain关键字可以对该查询sql进行分析，得到一张表如下：

![image-20230824095849403](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202308240958475.png)

其中我们主要关注的有：

- possible_keys：当前sql可能使用到的索引
- key：当前sql实际命中的索引
- key_len：当前索引占用的大小
- Extra：额外的优化的建议

> 我们可以通过key和key_len判断是否命中索引

- type：sql的连接的类型，性能由好到差为：NULL、system、const、eq_ref、ref、range、index、all

  - NULL：查询中没有表
  - system：查询MySQL内置自带的表
  - const：根据主键索引查询
  - eq_ref：根据主键索引查询或者唯一索引查询(只能返回一条数据，因为主键和唯一索引不能重复)
  - ref：索引查询(可能返回多条数据)
  - range：范围查询
  - index：索引树扫描
  - all：全盘扫描

  > 如果某个sql的type是index或者是all那么这个sql就需要优化



### 了解过索引吗？(什么是索引)

索引(index)是帮助MySQL**高效获取数据**的**数据结构**。在数据之外，数据库系统维护了满足特定查找算法的数据结构(B+树)，这些数据结构以某种方式引用数据，这样就可以在这些数据结构上实现高效的查找算法，这种数据结构就是索引。

### 索引的底层数据结构是什么样的？

索引底层的数据结构是B+树，B+Tree是在BTree的基础上的一种优化，**非叶子节点上只存储指针不存储数据，叶子节点上真正的存储数据，并且叶子节点之间使用双向指针相互连接**，innoDB存储引擎使用的就是B+树实现索引的

![image-20230824103228853](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202308241032008.png)

B+树相对于B树的优点：

- 磁盘读写代价B+树更低。比如我们需要查找6对应的数据，如果是B树因为B树的每个节点下的键值都由数据，会导致不需要的数据也会被读取到造成磁盘读写的浪费，而B+树只有叶子节点上保存数据，非叶子节点上保存的是指针，可以避免读取到不需要的数据
- 查询效率B+树稳定。因为非叶子节点上没有数据，每次查找都会从根节点出发直到叶子结点，所以查询的效率更稳定
- B+树更适合区间查询，因为B+树的叶子节点使用双向指针相互连接，比如查询6-36之间的数据只需要查找到6然后根据指针来进行查找即可。

### 什么是聚簇索引(聚集索引)什么是非聚簇索引(非聚集索引、二级索引)？

聚集索引：将数据与索引放到一块，索引结构的叶子结点保存了行数据；特点是索引必须有对应的整行数据并且只有一个。一般主键作为聚集索引。

二级索引：将数据与索引分开存储，索引结构的叶子节点关联的是对应的主键；特点是 索引结构的叶子节点关联的的主键 可以有多个。一般自定义的索引都是二级索引

聚集索引的选举规则：

- 如果存在主键，主键索引就是聚集索引。
- 如果不存在主键，将使用第一个唯一(UNIQUE)索引作为聚集索引。
- 如果表没有主键，或者没有合适的唯一索引，则InnoDB会自动生成一个rowid作为隐藏的聚集索引

![image-20230824150748657](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202308241507824.png)

### 什么是回表查询？

![image-20230824151652643](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202308241516807.png)

> select * from user where name = ‘Arm’;
>
> 由于name添加了索引，并且name不是主键也不是唯一索引而且表含有主键id，所以name就是二级索引，首先在二级索引中找到Arm对应的主键id，由于该sql语句查询的是*整行数据，所以需要再次查询聚集索引找到主键对应的整行数据。
>
> 综上回表查询就是：通过**二级索引**查找到主键值，然后到**聚集索引**中通过主键值查找到对应的整行数据，这个过程就是回表查询。



### 什么是覆盖索引？

> 覆盖索引：指查询使用了索引，并且需要返回的列 在该索引中已经全部能够找到。

![image-20230824154526112](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202308241545300.png)

### MySQL超大分页处理

> 在数据量比较大的时候，如果进行limit分页查询，在查询时候，越靠后分页查询的效率就越低。

例如 `select * from tb_user limit 9000000, 10;`需要耗时10秒多，因为执行的时候MySQL需要排序前9000010记录，但是仅仅返回9000000 - 9000010 条的记录，其他的记录丢弃，查询排序的代价非常大。

使用 覆盖索引+子查询 形式进行优化

```mysql
select *
from tb_user u,
	(select id from tb_user order by id limit 9000000,10) a # 根据id排序和返回id直接走的是覆盖索引
where u.id = a.id;
```




先分页查询数据的id字段，确定了id之后，再用子查询来过滤，只查询这个id列表中的数据就可以了。因为查询id的时候，走的覆盖索引，所以效率可以提升很多

### 创建索引的原则有哪些？

- 数据量大，查询频繁的字段。

  表中的数据要超过10万以上，我们才会创建索引，并且添加索引的字段是查询比较频繁的字段，一般也是像作为**查询条件where，排序字段order by或分组group的字段**这些。

- 尽量选择区分度较高的列作为索引，尽量建立唯一索引，区分度越高，使用索引的效率就越高。(例如性别和城市就不适合作为索引，因为会有大量重复的数据，区分度不高)

- 如果是字符串类型的字段，并且该字段比较长，可以针对该字段创建**前缀索引**(只截取前面几个字符串来创建索引)



### 什么情况下索引会失效？

<img src="https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202308241658008.png" alt="image-20230824165808831" style="zoom:50%;" />

- 违反最左前缀法则

  如果索引了多列，要遵循最左前缀法则。意思是查询必须从索引的最左前列开始，并且不能跳过索引中的列。

  匹配最左前缀法则，走索引的案例：

  ![image-20230824165829433](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202308241658519.png)

  违反最左前缀，索引失效的案例：

  ![image-20230824170127494](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202308241701612.png)

  如果符合最左法则，但是出现跳过某一列，只有最左索引生效(只命中了name一个索引)

  ![image-20230824170318295](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202308241703372.png)

- 范围查询右边的列会索引失效。

  ![image-20230824170601060](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202308241706249.png)

  > 范围查询右边的address的索引会失效，所以上面的查询只命中了name和status两个索引

- 不要在索引的字段上进行运算操作，否则索引将会失效。

  ![image-20230824171108620](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202308241711772.png)

- 字符串不加单引号，可能造成索引失效

  ![image-20230824171229791](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202308241712862.png)

  > 在查询的时候没有对字符串的status加上单引号，MySQL的查询会自动进行类型转换，造成索引失效。

- 以%开头的Like模糊查询，导致索引失效。如果仅仅是尾部模糊匹配，索引不会失效；如果是头部模糊匹配，索引会失效。

  ![image-20230824171513907](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202308241715986.png)

> 综上：什么情况下会导致索引失效？
>
> - 违反了最左前缀法则
> - 范围查询的右边的列，不能使用索引，因为索引失效了
> - 索引列上进行运算操作
> - 字符串不加单引号(类型转换)
> - 以%开头的模糊查询

### 事务的特性是什么？

事务是一组操作的集合，它是一个不可分割的单位，事务会把所有的操作视为一个整体一起向系统提交或撤销操作的请求，这些操作要么同时成功，要么同时失败。

事务的特性是ACID：原子性、一致性、隔离性、持久性。

1. 原⼦性（Atomicity）：事务是⼀个原⼦操作，要么全部提交，要么全部回滚。当⼀个事务执⾏期间发⽣故
障，操作系统会⾃动将其回滚到事务执⾏之前的状态，保证数据的⼀致性。
2. ⼀致性（Consistency）：事务执⾏结束后，数据必须保持⼀致性状态。在事务执⾏期间，数据库中的数据可
以处于中间状态，但在事务完成时必须保证数据的⼀致性。
3. 隔离性（Isolation）：数据库系统必须保证事务之间相互隔离，不会互相⼲扰。隔离级别不同，会影响到事务
的并发性和数据⼀致性，⽐如出现脏读、不可重复读、幻读等问题。
4. 持久性（Durability）：⼀旦事务提交，其所做的修改必须永久保存到数据库中。即使系统发⽣故障或宕机，
数据也能够保持不变。

### 并发事务带来哪些问题？怎么解决？MySQL默认的隔离级别是什么？

> 并发事务会导致的问题有：脏读，不可重复读，幻读，丢失更新。
>
> MySQL的隔离级别有：读未提交，读已提交，**可重复读**，串行化

并发事务的问题：

![image-20230824174214437](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202308241742624.png)

解决方法：对事务进行隔离

![image-20230824174356130](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202308241743208.png)

### undo log和redo log的区别

redo log日志记录的是数据页的物理变化，服务宕机可用来同步数据，而undo log 不同，它主要记录的是逻辑日志，当事务回滚时，通过逆操作恢复原来的数据，比如我们删除一条数据的时候，就会在undo log日志文件中新增一条delete语句，如果发生回滚就执行逆操作；

redo log保证了事务的持久性，undo log保证了事务的原子性和一致性



### 事务中的隔离性是如何保证的呢？(解释一下MVCC)

事务的隔离性是由锁和mvcc实现的。

> 锁：排它锁(一个事务获取了一个数据行的排它锁，其他事务就不能再获取该行的其他锁)
>
> mvcc：多版本并发控制
>
> MVCC的具体实现主要依赖于数据库中记录的**隐藏字段、undo log日志、readView**。
>
> 隐藏字段是指：在mysql中给每个表都设置了隐藏字段，有一个是trx_id(事务id)，记录每一次操作的事务id，是自增的；另一个字段是roll_pointer(回滚指针)，指向上一个版本的事务版本记录地址
>
> undo log主要的作用是记录回滚日志，存储老版本数据，在内部会形成一个版本链，在多个事务并行操作某一行记录，记录不同事务修改数据的版本，通过roll_pointer指针形成一个链表
>
> readView(读视图)解决的是一个事务查询选择版本的问题，在内部定义了一些匹配规则和当前的一些事务id判断该访问那个版本的数据，不同的隔离级别快照读是不一样的，最终的访问的结果不一样。如果是rc隔离级别，每一次执行快照读时生成ReadView，如果是rr隔离级别仅在事务中第一次执行快照读时生成ReadView，后续复用

### MySQL主从同步原理 

> MySQL主从复制的核心就是二进制日志(BINLOG)中记录了DDL（数据定义语言）语句和 DML（数据操纵语言）语句)，它的步骤是这样的：
>
> 第一：主库在事务提交时，会把数据变更记录在二进制日志文件 Binlog 中。
>
> 第二：从库读取主库的二进制日志文件 Binlog ，写入到从库的**中继日志** (Relay Log )。
>
> 第三：从库重做中继日志中的事件，将改变反映它自己的数据

### MySQL的分库分表

![image-20230825194845740](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202308251948931.png)

![image-20230825195028337](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202308251950497.png)

![image-20230825195215716](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202308251952913.png)

![image-20230825195410827](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202308251954945.png)

![image-20230825195454723](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202308251954941.png)



## 框架篇

### Spring中的Bean是线程安全的吗？

Spring 框架中的 Bean 是否线程安全，取决于其作用域和状态。

我们这里以最常用的两种作用域 prototype 和 singleton 为例介绍。几乎所有场景的 Bean 作用域都是使用默认的 singleton ，重点关注 singleton 作用域即可。

prototype 作用域下，每次获取都会创建一个新的 bean 实例，不存在资源竞争问题，所以不存在线程安全问题。singleton 作用域下，IoC 容器中只有唯一的 bean 实例，可能会存在资源竞争问题（取决于 Bean 是否有状态）。如果这个 bean 是有状态的话，那就存在线程安全问题（有状态 Bean 是指包含可变的成员变量的对象）。

不过，大部分 Bean 实际都是无状态（没有定义可变的成员变量）的（比如 Dao、Service），这种情况下， Bean 是线程安全的。

对于有状态单例 Bean 的线程安全问题，常见的有两种解决办法：

1. 在 Bean 中尽量避免定义可变的成员变量。
2. 在类中定义一个 `ThreadLocal` 成员变量，将需要的可变成员变量保存在 `ThreadLocal` 中（推荐的一种方式）。



### Bean的作用域有哪些？

Spring 中 Bean 的作用域通常有下面几种：

- **singleton** : IoC 容器中只有唯一的 bean 实例。Spring 中的 bean 默认都是单例的，是对单例设计模式的应用。
- **prototype** : 每次获取都会创建一个新的 bean 实例。也就是说，连续 `getBean()` 两次，得到的是不同的 Bean 实例。
- **request** （仅 Web 应用可用）: 每一次 HTTP 请求都会产生一个新的 bean（请求 bean），该 bean 仅在当前 HTTP request 内有效。
- **session** （仅 Web 应用可用） : 每一次来自新 session 的 HTTP 请求都会产生一个新的 bean（会话 bean），该 bean 仅在当前 HTTP session 内有效。
- **application/global-session** （仅 Web 应用可用）：每个 Web 应用在启动时创建一个 Bean（应用 Bean），该 bean 仅在当前应用启动时间内有效。
- **websocket** （仅 Web 应用可用）：每一次 WebSocket 会话产生一个新的 bean。



### 什么是AOP？你的项目中有没有使用到AOP？

> AOP 称为面向切面编程，用于将那些**与业务无关** 但却对多个对象产生影响的**公共行为和逻辑**，抽取并且封装成一个可重用的模块，这个模块被命名为切面(Aspect)，**减少系统中的重复代码，降低了模块之间的耦合度，同时提高了系统的可维护性。**

我的项目中使用AOP来记录请求日志，校验登录用户是否是管理员(配合自定义注解authCheck中的mustRole必须是admin才可以执行方法)。

先来介绍一下项目中使用AOP记录请求日志：首先编写一个类并使用@Aspect和@Component注解来表示这是一个AOP类，再定义一个方法并且使用@Around注解来标识在注解中填写表达式或者是切入点的方法，这里我直接填写表达式为 `* com.panda.controller.*.*(..)` 这个表达式可以匹配controller包中所有的方法，然后通过`RequestContextHolder`工具类来获取当前线程的Request相关的信息，获取Session得到当前的用户信息和请求的路径，记录请求日志。

校验当前用户是否是管理员使用AOP是在Around中写@annotation(authCheck)来拦截被authCheck注解标注的类，获取当前方法要求的用户权限，与该用户的角色进行判断，如果该用户是管理员则可以执行方法。



### Spring中的事务是如何实现的？

> Spring中的事务也是通过AOP来实现的，Spring提供了两种事务的使用方法：编程式事务和声明式事务

经常使用的是声明式事务，在类或者是方法上添加@Transactional注解来开启事务，Spring使用AOP在方法的前面开启事务，在执行方法完毕之后提交事务，如果方法出现异常则会回滚事务。所以Spring中的事务是通过AOP来实现的。



### Spring中事务失效的场景有哪些？

- 异常捕获处理

  > 在添加事务注解的方法中自己捕获异常并且在捕获的cache中没有抛出异常则会导致 事务不知道出现了异常 导致事务失效。
  >
  > 解决方法：在cache中再次抛出异常throw new RuntimeException("异常");

- 抛出检查异常

  > Spring默认只会回滚非检查异常运行时异常(检查异常：在方法上使用throws抛出异常)
  >
  > 解决方法：配置rollbackFor属性为Exception.class只要出现异常就会回滚

- 非public方法

  > Spring为方法创建代理、添加事务通知的前提条件是该方法是public的
  >
  > 解决方法：把方法改为public

- 同一个类里面调用(无法代理自己，可以通过AOP上下文对象(AopContext.currentProxy)获取一个当前类的代理类)



### Spring的Bean的生命周期

![Spring Bean 生命周期](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202309011033676.jpg)

![Spring Bean 生命周期](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202309072242285.jpg)



> 1. 通过BeanDefinition获取bean的定义信息
> 2. 调用构造函数实例化bean
> 3. bean的依赖注入(@Value、@Autowired...)
> 4. 处理Aware接口(实现以Aware结尾的接口，里面有方法需要我们重写，执行这些方法)
> 5. `BeanPostProcessor`前置处理器
> 6. 初始化方法(检查是否是InitializingBean、是否配置有自定义的init-method)
> 7. `BeanPostProcessor`后置处理器⭐️(可以在后置处理器中通过动态代理增强某个Bean)
> 8. 销毁Bean



### Spring中的循环引用

> 两个或两个以上的bean互相持有对方,最终形成闭环。比如A依赖于B,B依赖于A；循环依赖在spring中是允许存在，spring框架依据**三级缓存**已经解决了大部分的循环依赖(set方法注入)
>
> 创建A对象调用构造函数生成一个半成品的A对象，在设置对象属性，发现对象属性中有B对象，那么创建B对象调用B对象的构造函数生成一个半成品的B对象然后初始化B对象发现B对象中有A对象需要到Spring容器中找A对象但是A对象并没有初始化完毕，所以造成了循环依赖。

Spring解决循环依赖是通过三级缓存来解决的

![image-20230901110522841](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202309011105048.png)

| 缓存名称 | 源码名称              | 作用                                                           |
| -------- | --------------------- | -------------------------------------------------------------- |
| 一级缓存 | singletonObjects      | 单例池，缓存已经经历了完整的生命周期，已经初始化完成的bean对象 |
| 二级缓存 | earlySingletonObjects | 缓存早期的bean对象(生命周期还没有走完)                         |
| 三级缓存 | singletonFactories    | 缓存的是ObjectFactory，表示对象工厂，用来创建某个对象的        |

①一级缓存：单例池，缓存已经经历了完整的生命周期，已经初始化完成的bean对象

②二级缓存：缓存早期的bean对象（生命周期还没走完）

③三级缓存：缓存的是ObjectFactory，表示对象工厂，用来创建某个对象的

具体流程：

第一，先实例A对象，同时会创建ObjectFactory对象存入三级缓存singletonFactories  

第二，A在初始化的时候需要B对象，这个走B的创建的逻辑

第三，B实例化完成，也会创建ObjectFactory对象存入三级缓存singletonFactories  

第四，B需要注入A，通过三级缓存中获取ObjectFactory来生成一个A的对象同时存入二级缓存，这个是有两种情况，一个是可能是A的普通对象，另外一个是A的代理对象，都可以让ObjectFactory来生产对应的对象，这也是三级缓存的关键

第五，B通过从通过二级缓存earlySingletonObjects  获得到A的对象后可以正常注入，B创建成功，存入一级缓存singletonObjects  

第六，回到A对象初始化，因为B对象已经创建完成，则可以直接注入B，A创建成功存入一次缓存singletonObjects 

第七，二级缓存中的临时对象A清除 

### 构造方法出现了循环依赖怎么解决？

由于bean的生命周期中**构造函数是第一个执行的**，spring框架并不能解决构造函数的的依赖注入，可以使用@Lazy懒加载，什么时候需要对象再进行bean对象的创建



### SpringMVC的执行流程

![img](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202309011717921.png)

客户端（浏览器）发送请求， `DispatcherServlet`拦截请求。

2. `DispatcherServlet` 根据请求信息调用 `HandlerMapping` 。`HandlerMapping` 根据 uri 去匹配查找能处理的 `Handler`（也就是我们平常说的 `Controller` 控制器） ，并会将请求涉及到的拦截器和 `Handler` 一起封装。

3. `DispatcherServlet` 调用 `HandlerAdapter`适配器执行 `Handler` 。

4. `Handler` 完成对用户请求的处理后，会返回一个 `ModelAndView` 对象给`DispatcherServlet`，`ModelAndView` 顾名思义，包含了数据模型以及相应的视图的信息。`Model` 是返回的数据对象，`View` 是个逻辑上的 `View`。

5. `ViewResolver` 会根据逻辑 `View` 查找实际的 `View`。

6. `DispaterServlet` 把返回的 `Model` 传给 `View`（视图渲染）。

7. 把 `View` 返回给请求者（浏览器）



### Spring MVC 的核心组件有哪些？

- **`DispatcherServlet`**：**核心的中央处理器**，负责接收请求、分发，并给予客户端响应。

- **`HandlerMapping`**：**处理器映射器**，根据 uri 去匹配查找能处理的 `Handler` ，并会将请求涉及到的拦截器和 `Handler` 一起封装。

- **`HandlerAdapter`**：**处理器适配器**，根据 `HandlerMapping` 找到的 `Handler` ，适配执行对应的 `Handler`；

- **`Handler`**：**请求处理器**，处理实际请求的处理器。

- **`ViewResolver`**：**视图解析器**，根据 `Handler` 返回的逻辑视图 / 视图，解析并渲染真正的视图，并传递给 `DispatcherServlet` 响应客户端



### SpringBoot的自动配置原理

在Spring Boot项目中的引导类上有一个注解@SpringBootApplication，这个注解是对三个注解进行了封装，分别是：

- @SpringBootConfiguration

- @EnableAutoConfiguration

- @ComponentScan

其中`@EnableAutoConfiguration`是实现自动化配置的核心注解。 

该注解通过`@Import`注解导入对应的配置选择器。关键的是内部就是读取了该项目和该项目引用的Jar包的的classpath路径下**META-INF/spring.factories**文件中的所配置的类的全类名。 

在这些配置类中所定义的Bean会根据条件注解所**指定的条件来决定**是否需要将其导入到Spring容器中。

一般条件判断会有像`@ConditionalOnClass`这样的注解，判断是否有对应的class文件，如果有则加载该类，把这个配置类的所有的Bean放入spring容器中使用。



### Spring && Spring MVC && SpringBoot 常用注解有哪些？

![image-20230901173331454](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202309011733641.png)

![image-20230901173457417](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202309011734522.png)

![image-20230901173707590](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202309011737694.png)



> https://javaguide.cn/system-design/framework/spring/spring-common-annotations.html



### MyBatis

> https://javaguide.cn/system-design/framework/mybatis/mybatis-interview.html



### 项目中使用的Spring Cloud组件有哪些？

- 注册中心和配置中心：nacos：一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。
- RPC远程调用框架：Dubbo
- 网关：Spring Cloud Gateway：用于网关服务，实现请求的转发和路由。
- 服务保护：Sentinel(在项目中暂时没有使用到)以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。



### 服务注册和发现是什么意思？Spring Cloud如何实现服务注册发现？

服务注册：服务提供者需要把自己的信息注册到注册中心中，由注册中心来保存这些信息，比如服务名称、ip、端口等等

服务发现：消费者向注册中心拉取服务列表信息，如果服务的提供者有集群，则消费者会使用负载均衡选择一个服务发起调用

服务监控：服务提供者会每隔一段时间向注册中心发送心跳，汇报健康状态，如果注册中心超过一定的时间没有收到心跳则会被剔除掉



### nacos和Eureka的区别

api平台项目就是采用的nacos作为注册中心，选择nacos还要一个重要原因就是它支持配置中心，不过nacos作为注册中心，也比eureka要方便好用一些，主要相同不同点在于几点：

- 共同点

Nacos与eureka都支持服务注册和服务拉取，都支持服务提供者心跳方式做健康检测

- Nacos与Eureka的区别

①Nacos支持服务端主动检测提供者状态：临时实例采用心跳模式，非临时实例采用主动检测模式

②临时实例心跳不正常会被剔除，非临时实例则不会被剔除

③Nacos支持服务列表变更的消息推送模式，服务列表更新更及时

④Nacos集群默认采用AP方式，当集群中存在非临时实例时，采用CP模式；Eureka采用AP方式

### 什么是CAP理论？

CAP主要是在分布式项目下的一个理论。包含了三项，一致性、可用性、分区容错性

- 一致性(Consistency)是指更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致(强一致性)，不能存在中间状态。

- 可用性(Availability) 是指系统提供的服务必须一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。

- 分区容错性(Partition tolerance) 是指分布式系统在遇到任何网络分区故障时，仍然需要能够保证对外提供满足一致性和可用性的服务，除非是整个网络环境都发生了故障。



## 消息队列

### 消息队列可以用来干什么，在你的项目中有使用到吗？

异步、解耦、削峰

在我曾经的一个项目中有主要使用到消息队列的异步的特性，当时是一个秒杀优惠券的功能，为了提高秒杀的性能 我使用到了redis缓存优惠券的库存，并且配合Lua脚本实现操作redis的原子性，在判断库存充足的情况下，会减少库存之后就向消息队列中发送下单优惠券的消息，然后就直接返回下单成功，消息的订阅者就监听消息队列发现有消息则执行具体的下单操作修改数据库的信息，完成下单的完整操作实现业务的异步，提高接口的响应速度。



> 引入消息队列可能会对系统造成的影响：
>
> 可用性降低，复杂度上升，又带来一系列的重复消费，顺序消费，消息堆积的问题。这些都有对应的解决方案



### RocketMQ如何保证消息的顺序性？

生产者端发送消息使用哈希取余算法(根据业务的id得到hashCode然后对队列的大小取余得到该消息应该放到哪个队列中)，消费者端应该使用单线程模型，在SpringBoot中应该指定@RocketMQListener中消费者的模式为单线程即一个队列只对应一个线程来处理消费，这样就可以保证消息的顺序消费。

### 如何避免消息的重复消费？

在生产者发送消息的时候，可以给消息指定一个唯一的业务key，在消费者端接收的时候直接保存到数据库或者缓存的去重表中，在这个去重表中key是唯一索引，如果保存数据库失败那么就说明该消息已经消费过了，我们直接返回通过就ok了，如果没有该消息那么则会创建成功也会直接返回成功。

### 如何解决消息大量堆积的问题？

消息堆积的问题产生的根源就是：生产者生产的速度相对于消费者消费的速度过快，我们可以对生产者进行限流操作，限制生产者的生产速度，当然最快解决大量消息堆积的方法就是添加多个消费者，在添加消费者的时候要注意必须保证主题中的队列数量大于等于消费者否则就会出现某个消费者没有对应的队列，所以在添加消费者的同时也要添加主题中的队列，这样可以快速解决大量消息堆积的问题，对了，同时我们也可以给消费者添加消费线程来加快消费的进度。

## 常见集合篇

### 数组

> 数组(Array)是一种使用连续的内存空间存储相同类型的数据的线性数据结构。

### 为什么Java的数组下标从0开始而不是从1开始？

首先在回答这个问题之前，我们需要先了解数据在堆内存中的数据结构，当我们创建了一个数组比如 `int[] array = {1,2,3}` array变量是保存在栈中的并且保存的是数组对象的首地址，并且数组是连续的，int占用的内存大小是4个字节，

数组的寻址公式就是：首地址+i*数组中元素类型的大小；对应上面的array就是:`首地址+i*4`;如果数组下标从1开始，那么寻址公式就变为了`首地址+(i-1)*4` 多了一个减一的操作，对于CPU来说就多了一次指令，相对来说会影响一部分的性能。

### ArrayList底层的实现原理是什么？

>  ArrayList底层是用动态的数组实现的。

当我们创建一个ArrayList对象的时候，底层其实是一个Object数组并且在我们创建的时候进行了初始化为空数组；
当我们第一次调用add方法进行添加元素的时候，内部会对数组进行一个长度为10的扩容，扩容完毕之后再进行元素的添加。
然后第二次调用add方法进行添加元素的时候，因为当前元素大小为2没有超过10所以并不需要扩容。
直到添加到第10个元素之后，当添加到第11个元素的时候，因为超过数组的长度10，所以会按照原先数组长度的1.5倍进行扩容，扩容完毕之后再进行元素的添加。

### 如何实现数组和List之间的转换？

> 数组转List：
>
> 可以使用Arrays.toList()方法来使数组转换为List，不过转换得到的List并不是java.util.ArrayList，而是Arrays的一个内部类，该内部类实现了AbstractList接口但是并没有重写add、remove、clear方法，所以使用这种方法得到的集合不能进行修改。
>
> 另一种方法是使用stream流来把数组收集为List集合，这也是比较推荐的做法。
>
> 还有一种方法是使用Arrays.toList()得到的集合放到new ArrayList()的构造函数中，这样就可以得到一个完整的ArrayList对象了。
>
> List转数组：
>
> 可以调用集合的toArray(T[] array)方法，可以传入一个类型一致、长度为0的空数组(这里只是为了说明返回的类型起到了一个模板的作用，0是为了节省空间)。如果不传递参数那么返回的则是Object类型的数组。

### 数组调用Arrays.toList()转换List之后修改数组会影响List吗？

> 会影响List的。
>
> 这个我曾经看过Arrays.toList()的源码，在调用该方法之后内部返回了一个ArrayList对象，但是这个ArrayList是Arrays类的内部类，该类的构造方法中接收一个数组，然后会判断数组是否是空，如果不是空则会直接把该数组赋值给内部的数组。它们指向的是同一个地址，所以修改数组会影响到使用该方法得到的List。

### List用toArray转数组后，如果修改了List内容，数组受影响吗？

> list用了toArray转数组后，如果修改了list内容，数组不会影响，当调用了toArray以后，在底层是它是进行了数组的拷贝，跟原来的元素就没啥关系了，所以即使list修改了以后，数组也不受影响

### ArrayList与LinkedList的区别

- **是否保证线程安全：** `ArrayList` 和 `LinkedList` 都是不同步的，也就是不保证线程安全；

  如果需要保证线程安全，有两种解决方案：

  - 在方法内部使用，局部变量可以保证线程安全的。
  - 使用线程安全的ArrayList和LinkedList：使用Collections.synchronizedList(new ArrayLisy<>()); 把List包装为线程安全的List。

- **底层数据结构：** `ArrayList` 底层使用的是 **`Object` 数组**；`LinkedList` 底层使用的是 **双向链表** 数据结构

- **插入和删除是否受元素位置的影响**：

  - `ArrayList` 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。 比如：执行`add(E e)`方法的时候， `ArrayList` 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是 O(1)。但是如果要在指定位置 i 插入和删除元素的话（`add(int index, E element)`），时间复杂度就为 O(n)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。
  - `LinkedList` 采用链表存储，所以在头尾插入或者删除元素不受元素位置的影响（`add(E e)`、`addFirst(E e)`、`addLast(E e)`、`removeFirst()`、 `removeLast()`），时间复杂度为 O(1)，如果是要在指定位置 `i` 插入和删除元素的话（`add(int index, E element)`，`remove(Object o)`,`remove(int index)`）， 时间复杂度为 O(n) ，因为需要先移动到指定位置再插入和删除。

- **是否支持快速随机访问：** `LinkedList` 不支持高效的随机元素访问，而 `ArrayList`（实现了 `RandomAccess` 接口） 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于`get(int index)`方法)。

- **内存空间占用：** `ArrayList` 的空间浪费主要体现在在 list 列表的结尾会预留一定的容量空间，而 LinkedList 的空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放直接后继和直接前驱以及数据）。

### 说一下**HashMap**的实现原理？

> HashMap的数据结构： 底层使用hash表数据结构，即数组和链表或红黑树


1. 当我们往HashMap中put元素时，利用key的hashCode重新hash计算出当前对象的元素在数组中的下标
2. 存储时，如果出现hash值相同的key，此时有两种情况。
 a. 如果key相同，则覆盖原始值；
    b. 如果key不同（出现冲突），则将当前的key-value放入链表或红黑树中
3. 获取时，直接找到hash值对应的下标，在进一步判断key是否相同，从而找到对应值

![image-20230906160611492](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202309061606696.png)

### HashMap的jdk1.7和jdk1.8有什么区别

JDK1.8之前采用的是拉链法。拉链法：将链表和数组相结合。也就是说创建一个链表数组，数组中每一格就是一个链表。若遇到哈希冲突，则将冲突的值加到链表中即可。

jdk1.8在解决哈希冲突时有了较大的变化，当链表长度大于为8时 并且 数组长度**达到64时**，将链表转化为红黑树，以减少搜索时间。

### **HashMap**的**put**方法的具体流程

![image-20230906163433311](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202309061634392.png)

1. 判断键值对数组table是否为空或为null，否则执行resize()进行扩容（初始化长度为16的数组）
2. 根据键值key计算hash值得到数组索引
3. 判断table[i]==null，条件成立，直接新建节点添加
4. 如果table[i]==null ,不成立
4.1 判断table[i]的首个元素是否和key一样，如果相同直接覆盖value
4.2 判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对
4.3 遍历table[i]，链表的尾部插入数据，然后判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操 作，遍历过程中若发现key已经存在直接覆盖value
5. 插入成功后，判断实际存在的**键值对**数量size是否超多了最大容量threshold（数组长度*0.75），如果超过，进行扩容。

### HashMap的扩容机制

在添加元素或初始化的时候需要调用resize方法进行扩容，第一次添加数据初始化数组长度为16，以后每次每次扩容都是达到了扩容阈值（数组长度 *0.75）

每次扩容的时候，都是扩容之前容量的2倍；

扩容之后，会新创建一个数组，需要把老数组中的数据挪动到新的数组中没有hash冲突的节点，则直接使用 e.hash & (newCap - 1) 计算新数组的索引位置

如果是红黑树，走红黑树的添加

如果是链表，则需要遍历链表，可能需要拆分链表，判断(e.hash &oldCap)是否为0，该元素的位置要么停留在原始位置，要么移动到原始位置+增加的数组大小这个位置上

### **hashMap**的寻址算法 

1. 首先获取key的hashCode值，然后右移16位 异或运算 原来的hashCode值，主要作用就是使原来的hash值更加均匀，减少hash冲突
2. (n-1)&hash : 得到数组中的索引，代替取模，性能更好，数组长度必须是2的n次幂

### 为何**HashMap**的数组长度一定是**2**的次幂？ 

1. 计算索引时效率更高：如果是 2 的 n 次幂可以使用位与运算代替取模
2. 扩容时重新计算索引效率更高： hash & oldCap == 0 的元素留在原来位置，否则新位置 = 旧位置 + oldCap

### **HashSet**与**HashMap**的区别

(1)HashSet实现了Set接口, 仅存储对象; HashMap实现了 Map接口, 存储的是键值对.

(2)HashSet底层其实是用HashMap实现存储的, HashSet封装了一系列HashMap的方法. 依靠HashMap来存储元素值,(利用hashMap的key键进行存储), 而value值默认为同一个Object对象. 所以HashSet也不允许出现重复值, 判断标准和HashMap判断标准相同, 两个元素的hashCode相等并且通过equals()方法返回true.



## 并发编程篇

![image-20230906170843331](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202309061708511.png)

### 线程的基础知识：

### 什么是线程和进程?

**进程**是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。

在 Java 中，当我们启动 main 函数时其实就是启动了一个 JVM 的进程，而 main 函数所在的线程就是这个进程中的一个线程，也称主线程。

**线程**与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。

> **线程是进程划分成的更小的运行单位。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。线程执行开销小，但不利于资源的管理和保护；而进程正相反。**

区别：

- 进程是正在运行程序的实例，进程中包含了线程，每个线程执行不同的任务

- 不同的进程使用不同的内存空间，在当前进程下的所有线程可以共享内存空间

- 线程更轻量，线程上下文切换成本一般上要比进程上下文切换低(上下文切换指的是从一个线程切换到另一个线程) 

### 并发与并行的区别

- **并发**：两个及两个以上的作业在同一 **时间段** 内执行。
- **并行**：两个及两个以上的作业在同一 **时刻** 执行。

> 最关键的点是：是否是 **同时** 执行。

### 创建线程的方式有哪些？

共有四种方式可以创建线程，分别是：

继承Thread类、

实现Runnable接口、

实现Callable接口、

线程池创建线程(项目中使用)

```java
package com.hm.createThread;

public class MyThreadDemo01 extends Thread{


    @Override
    public void run() {
        System.out.println(Thread.currentThread().getName()+" MyThread run ...");
    }

    public static void main(String[] args) {
        MyThreadDemo01 myThreadDemo01 = new MyThreadDemo01();
        MyThreadDemo01 myThreadDemo02 = new MyThreadDemo01();
        myThreadDemo01.start();
        myThreadDemo02.start();

        System.out.println(Thread.currentThread().getName()+" MainThread run ...");
    }
}

```

```java
package com.hm.createThread;

public class MyThreadDemo02 implements Runnable{
    @Override
    public void run() {
        System.out.println("Runnable Thread run ...");
    }

    public static void main(String[] args) {
        new Thread(new MyThreadDemo02()).start();
    }
}

```

```java
package com.hm.createThread;

import java.util.concurrent.Callable;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.FutureTask;

public class MyThreadDemo03 implements Callable<String> {
    @Override
    public String call() throws Exception {
        return "Callable thread run ...";
    }

    public static void main(String[] args) throws ExecutionException, InterruptedException {
        FutureTask<String> stringFutureTask = new FutureTask<>(new MyThreadDemo03());
        new Thread(stringFutureTask).start();
        System.out.println(stringFutureTask.get());
    }
}

```

```java
package com.hm.createThread;

import java.util.concurrent.ArrayBlockingQueue;
import java.util.concurrent.Executors;
import java.util.concurrent.ThreadPoolExecutor;
import java.util.concurrent.TimeUnit;

public class MyThreadDemo04 {
    public static void main(String[] args) {
        ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(10,
                10,
                0,
                TimeUnit.MILLISECONDS,
                new ArrayBlockingQueue<>(10),
                Executors.defaultThreadFactory(),
                new ThreadPoolExecutor.AbortPolicy());
        threadPoolExecutor.submit(()-> System.out.println(Thread.currentThread().getName()+"Thread Pool run ..."));
        threadPoolExecutor.shutdown();

    }
}

```

### **runnable** 和 **callable** 有什么区别

1. Runnable 接口run方法没有返回值；Callable接口call方法有返回值，是个泛型，和Future、FutureTask配合可以用来获取异步执行的结果

2. Callalbe接口支持返回执行结果，需要调用FutureTask.get()得到，此方法会阻塞主进程的继续往下执行，如果不调用不会阻塞。
3. Callable接口的call()方法允许抛出异常；而Runnable接口的run()方法的异常只能在内部消化，不能继续上抛



### 线程的 **run()**和 **start()**有什么区别？

start(): 用来启动线程，通过该线程调用run方法执行run方法中所定义的逻辑代码。start方法只能被调用一次。

run(): 封装了要被线程执行的代码，可以被调用多次。

### 可以直接调用 Thread 类的 run 方法吗？

> **调用 `start()` 方法方可启动线程并使线程进入就绪状态，直接执行 `run()` 方法的话不会以多线程的方式执行。**

### 说说线程包含哪些状态?

Java 线程在运行的生命周期中的指定时刻只可能处于下面 6 种不同状态的其中一个状态：

- 新建NEW
- 可运行RUNNABLE
- 阻塞BLOCKED
- 等待WAITING
- 时间等待TIME_WAITING
- 终止TERMINATED

### 线程状态之间是如何变化的？

![image-20230906203311735](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202309062033954.png)

- 创建线程对象是**新建状态**
- 调用start()方法转变为**可执行状态**
- 线程获取到了CPU的执行权，执行结束是**终止状态**
- 在可执行状态的过程中，如果没有获取到CPU的执行权，可能会切换到其他的状态
  - 如果没有获取到锁会进入**阻塞状态**，获取到锁再切换为可执行状态
  - 如果线程调用了wait()方法进入**等待状态**，其他线程调用notify()唤醒后切换为可执行状态
  - 如果线程调用了sleep()方法，则会进入**计时等待状态**，到时间后可切换为可执行状态

### 如何保证线程的顺序执行？

比如说现在我们创建了3个线程分别是t1、t2、t3，我们需要保证t1、t2、t3按照顺序执行。

首先最简单的方法就是在t2线程中调用t1.join()方法等待t1线程结束；在t3线程中调用t2.join()方法等待t2线程结束。

```java
package com.hm.createThread;

public class OrderlyThread {
    public static void main(String[] args) {
        Thread t1 = new Thread(() -> {
            System.out.println("t1");
        });
        Thread t2 = new Thread(() -> {
            try {
                // 等待t1线程死亡。
                t1.join();
            } catch (InterruptedException e) {
                throw new RuntimeException(e);
            }
            System.out.println("t2");
        });
        Thread t3 = new Thread(() -> {
            try {
                // 等待t2线程死亡。
                t2.join();
            } catch (InterruptedException e) {
                throw new RuntimeException(e);
            }
            System.out.println("t3");
        });
        t1.start();
        t2.start();
        t3.start();
    }
}

```



### notify和notifyAll有什么区别

- notify随机唤醒一个wait线程
- notifyAll唤醒所有的wait线程



### sleep() 方法和 wait() 方法对比

**共同点**：两者都可以暂停线程的执行。

**区别**：

- **`sleep()` 方法没有释放锁，而 `wait()` 方法释放了锁** 。
- `wait()` 通常被用于线程间交互/通信，`sleep()`通常被用于暂停执行。
- `wait()` 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 `notify()`或者 `notifyAll()` 方法。`sleep()`方法执行完成后，线程会自动苏醒，或者也可以使用 `wait(long timeout)` 超时后线程会自动苏醒。
- `sleep()` 是 `Thread` 类的静态本地方法，`wait()` 则是 `Object` 类的本地方法。



### 如何停止一个正在运行的线程？

- 使用退出标志，使线程正常退出。定义一个volatile(保证变量可见性)的flag变量
- 使用线程的stop()方法强行停止(不推荐)
- 使用interrupt方法中断线程



### 线程中并发安全的问题：

### 讲一下**synchronized**关键字的底层原理？

回答如下：

> Synchronized【对象锁】采用互斥的方式让**`同一时刻至多只有一个线程`**能持有【对象锁】
>
> 它的底层由`monitor`实现的，monitor是jvm级别的对象（ C++实现），线程获得锁需要使用对象（锁）关联monitor
>
> 在monitor内部有三个属性，分别是`owner、entrylist、waitset`
>
> - owner是关联的获得锁的线程，并且只能关联一个线程；
>
> - entrylist关联的是处于阻塞状态的线程；
>
> - waitset关联的是处于Waiting状态的线程
>
> 

![image-20230907162933463](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202309071629620.png)
Monitor内部具体的存储结构：
Owner：存储当前**`获取锁的线程`**，只能有一个线程可以获取
EntryList：**关联没有抢到锁的线程**，处于Blocked状态的线程
WaitSet：**关联调用了wait方法的线程**，处于Waiting状态的线程

具体的流程：

> 1. 代码进入synchorized代码块，先让lock（对象锁）关联的monitor，然后判断Owner是否有线程持有
>
> 2. 如果没有线程持有，则让当前线程持有，表示该线程获取锁成功
>
> 3. 如果有线程持有，则让当前线程进入entryList进行阻塞，如果Owner持有的线程已经释放了锁，在EntryList中的线程去竞争锁的持有权（非公平）
>
> 4. 如果代码块中调用了wait()方法，则会进去WaitSet中进行等待

### 什么是CAS？

CAS 的全称是 **Compare And Swap（比较与交换）** ，用于实现乐观锁，被广泛应用于各大框架中`(AbstractQueuedSynchronizer（AQS框架）AtomicXXX类)`CAS 的思想很简单，就是用一个**预期值和要更新的变量值进行比较**，**两值相等才会进行更新**。

CAS 是一个原子操作，底层依赖于一条 CPU 的原子指令。

> **原子操作** 即最小不可拆分的操作，也就是说操作一旦开始，就不能被打断，直到操作完成。

CAS 涉及到三个操作数：

- **V**：要更新的变量值(Var)
- **E**：预期值(Expected)
- **N**：拟写入的新值(New)

**举一个简单的例子**：线程 A 要修改变量 i 的值为 6 ，i 原值为 1（V = 1，E=1，N=6，假设不存在 ABA 问题）。

1. i 与 1 进行比较，如果相等， 则说明没被其他线程修改，可以被设置为 6 。
2. i 与 1 进行比较，如果不相等，则说明被其他线程修改，当前线程放弃更新，CAS 操作失败。

当多个线程同时使用 CAS 操作一个变量时，只有一个会胜出，并成功更新，其余均会失败，但失败的线程并不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作。

### 谈谈你对volatile关键字的理解

一旦一个共享变量(类的成员变量、类的静态成员变量)被volatile修饰后，那么就具备了两层语义：

- **保证线程之间的可见性**
- **禁止进行指令重排序**

保证线程之间的可见性：

> 用volatile关键字修饰的共享变量，能够防止编译器的优化发生，让一个线程对共享变量的修改对另一个线程可见

禁止进行指令重排序：

> 用 volatile 修饰共享变量会在读、写共享变量时加入不同的屏障，阻止其他读写操作越过屏障，从而达到阻止重排序的效果



### 什么是AQS？

- AQS是多线程中的**抽象队列同步器**。是一种锁机制，它是做为一个基础框架使用的，像是ReentrantLock、Semaphore、CountDownLatch都是基于AQS实现的
- AQS内部维护了一个**先进先出的双向队列**，队列中存储排队的线程
- 在AQS内部还有一个**属性status**，这个status代表是否有锁的状态，默认是0(无锁状态)，如果队列中的某一个线程修改为1，则当前线程就获取到了资源，其他线程进入FIFO队列中等待
- 对status的修改操作使用的是CAS，保证了多个线程修改的情况下的原子性

![image-20230908094138355](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202309080941517.png)



### ReentrantLock的实现原理

ReentrantLock翻译过来是可重入锁，一个线程调用lock获取锁之后再次调用lock不会阻塞，相对于synchronized它具备以下特点：

- 可中断

- 可以设置超时时间

- 可以设置公平锁

- 支持多个条件变量

- 与synchronized一样，都支持重入

> ReentrantLock主要利用CAS+AQS队列来实现。它支持公平锁和非公平锁，两者的实现 类似。



### synchronized和Lock有什么区别？

语法层面：

- synchronized 是关键字，源码在 jvm 中，用 c++ 语言实现

- Lock 是接口，源码由 jdk 提供，用 java 语言实现

- 使用 synchronized 时，退出同步代码块锁会自动释放，而使用 Lock 时，需要手动调用 unlock 方法释放锁

功能层面：

- 二者均属于悲观锁、都具备基本的互斥、同步、锁重入功能

- Lock 提供了许多 synchronized 不具备的功能，例如获取等待状态、公平锁、可打断、可超时、多条件变量

- Lock 有适合不同场景的实现，如 ReentrantLock， ReentrantReadWriteLock

性能层面：

- 在没有竞争时，synchronized 做了很多优化，如偏向锁、轻量级锁

- 在竞争激烈时，Lock 的实现通常会提供更好的性能



### 死锁产生的条件是什么？

死锁：一个线程需要同时获取多把锁，这时就容易发生死锁

> 例如：
>
> t1 线程获得A对象锁，接下来想获取B对象的锁
>
> t2 线程获得B对象锁，接下来想获取A对象的锁

怎么诊断出程序是否出现了死锁？

使用jdk自带的工具：jps和 jstack

首先使用jps查看java线程id

使用jstack -l xxx 查看日志检查死锁



### 聊一下ConcurrentHashMap

jdk1.7：

存储结构：

![image-20230908111512527](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202309081115793.png)

- 提供了一个segment数组，在初始化ConcurrentHashMap 的时候可以指定数组的长度，默认是16，一旦初始化之后中间不可扩容 

- 在每个segment中都可以挂一个HashEntry数组，数组里面可以存储具体的元素，HashEntry数组是可以扩容的 

- 在HashEntry存储的数组中存储的元素，如果发生冲突，则可以挂单向链表

存储流程：

![image-20230908112552188](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202309081125290.png)

- 先去计算key的hash值，然后确定segment数组下标

- 再通过hash值确定hashEntry数组中的下标存储数据

- 在进行操作数据的之前，会先判断当前segment对应下标位置是否有线程进行操作，为了线程安全使用的是ReentrantLock进行加锁，如果获取锁是被会使用cas自旋锁进行尝试



jdk1.8：

在JDK1.8中，放弃了Segment臃肿的设计，数据结构跟HashMap的数据结构是一样的：数组+红黑树+链表

采用 CAS + Synchronized来保证并发安全进行实现

- CAS控制数组节点的添加

- synchronized只锁定当前链表或红黑二叉树的首节点，只要hash不冲突，就不会产生并发的问题 , 效率得到提升

![image-20230908113146272](https://blog-images-1309758663.cos.ap-nanjing.myqcloud.com/202309081131315.png)

### 线程池的内容：

### 说一下线程池的核心参数（线程池的执行原理知道吗？）

```java
public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue,
                              ThreadFactory threadFactory,
                              RejectedExecutionHandler handler) ;
```

- corePoolSize 核心线程

- maximumPoolSize 最大有多少个线程 = (核心线程+临时线程) 

- keepAliveTime 生存时间 - 临时线程的生存时间，生存时间内没有新任务，此线程资源会释放

- unit 时间单位 - 临时线程的生存时间单位，如秒、毫秒等

- workQueue - 当没有空闲核心线程时，新来任务会加入到此队列排队，队列满会创建临时线程执行任务

- threadFactory 线程工厂 - 可以定制线程对象的创建，用于创建线程

- handler 拒绝策略 - 当所有线程都在繁忙，workQueue 也放满时，会触发拒绝策略

### 如何确定核心线程数？

在设置核心线程数之前，需要先熟悉一些执行线程池执行任务的类型

IO密集型任务

一般来说：文件读写、DB读写、网络请求等

推荐：核心线程数大小设置为2N+1 （N为计算机的CPU核数）

CPU密集型任务

一般来说：计算型代码、Bitmap转换、Gson转换等

推荐：核心线程数大小设置为N+1 （N为计算机的CPU核数）

### ThreadLocal 有什么用？

**`ThreadLocal`类主要解决的就是让每个线程绑定自己的值，可以将`ThreadLocal`类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。**

如果你创建了一个`ThreadLocal`变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是`ThreadLocal`变量名的由来。他们可以使用 `get()` 和 `set()` 方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。

### ThreadLocal 内存泄露问题是怎么导致的？

`ThreadLocalMap` 中使用的 key 为 `ThreadLocal` 的弱引用，而 value 是强引用。所以，如果 `ThreadLocal` 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。

这样一来，`ThreadLocalMap` 中就会出现 key 为 null 的 Entry。假如我们不做任何措施的话，value 永远无法被 GC 回收，这个时候就可能会产生内存泄露。`ThreadLocalMap` 实现中已经考虑了这种情况，在调用 `set()`、`get()`、`remove()` 方法的时候，会清理掉 key 为 null 的记录。使用完 `ThreadLocal`方法后最好手动调用`remove()`方法

> 弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它 所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。
